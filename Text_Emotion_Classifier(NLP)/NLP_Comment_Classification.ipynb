{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkqpwsImGGDx/pUEC8oQAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skl30misha/data-science-portfolio/blob/main/Text_Emotion_Classifier(NLP)/NLP_Comment_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "BtZnC6HRzFgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itVFtfgQyaZ0",
        "outputId": "1aeb97ff-6d03-4b1e-8fe5-d4e38943b21c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/NLP')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('amazon.csv')\n",
        "df.head()\n",
        "df_text = df[\"reviews.text\"].dropna()\n"
      ],
      "metadata": {
        "id": "eZxYNN7RzKzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning text stopwords"
      ],
      "metadata": {
        "id": "xITTkdHG2G4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "df['clean_text'] = df_text.apply(clean_text)\n",
        "df_text = df['reviews.text'].dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isRMdLHd2QaM",
        "outputId": "973e5913-52c3-4768-9740-cd5b7a70e998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization and Lemmatization of text"
      ],
      "metadata": {
        "id": "Vad0Uhid_1aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def spacy_token_lemma(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "df['lemmas'] = df['clean_text'].apply(spacy_token_lemma)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "df[\"lemmas_text\"]=df[\"lemmas\"].apply(lambda x: \" \".join(x))\n"
      ],
      "metadata": {
        "id": "QsMLshhc_5z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Sentiment Based on Ratings"
      ],
      "metadata": {
        "id": "V_ABha8nitx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "\n",
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# 1. ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# 2. Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸\n",
        "def vader_sentiment(text):\n",
        "    score = analyzer.polarity_scores(str(text))['compound']\n",
        "    if score >= 0.05:\n",
        "        return 'positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# 3. ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð°Ñ‚Ð°Ñ„Ñ€ÐµÐ¹Ð¼Ð°\n",
        "df['sentiment'] = df['clean_text'].apply(vader_sentiment)\n",
        "\n",
        "# 4. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹\n",
        "print(df[['clean_text', 'sentiment']].head())\n",
        "print(df['sentiment'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "C-KbJFnqjwUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f06b43-d051-45bc-de09-5c0d5b0cc81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.4.26)\n",
            "                                          clean_text sentiment\n",
            "0  thought would big small paper turn like palm t...  positive\n",
            "1             kindle light easy use especially beach  positive\n",
            "2  didnt know much id use kindle went lower end i...  positive\n",
            "3  happy purchase caught sale really good price n...  positive\n",
            "4  solid entry level kindle great kids gifted kid...  positive\n",
            "sentiment\n",
            "positive    4557\n",
            "negative     226\n",
            "neutral      217\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# check"
      ],
      "metadata": {
        "id": "Gqo4HajxeL6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"I hate this website. It's so frustrating!\"\n",
        "\n",
        "score = analyzer.polarity_scores(sample)\n",
        "compound = score['compound']\n",
        "\n",
        "if compound >= 0.05:\n",
        "    sentiment = 'positive'\n",
        "elif compound <= -0.05:\n",
        "    sentiment = 'negative'\n",
        "else:\n",
        "    sentiment = 'neutral'\n",
        "\n",
        "print(f\"Text: {sample}\")\n",
        "print(f\"Compound score: {compound}\")\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "id": "4_p-XNgheOa5",
        "outputId": "420937a1-4160-4818-8f57-a2143a17345a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I hate this website. It's so frustrating!\n",
            "Compound score: -0.8286\n",
            "Predicted Sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "EPo3Ji_QkFEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    score = analyzer.polarity_scores(text)['compound']\n",
        "    if score >= 0.05:\n",
        "        sentiment = 'Positive ðŸ˜Š'\n",
        "    elif score <= -0.05:\n",
        "        sentiment = 'Negative ðŸ˜ '\n",
        "    else:\n",
        "        sentiment = 'Neutral ðŸ˜'\n",
        "    return f\"Sentiment: {sentiment} (score: {score:.2f})\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=analyze_sentiment,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Enter a comment here...\"),\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"VADER Sentiment Analyzer\",\n",
        "    description=\"Type your comment and see the sentiment prediction (positive, neutral, negative).\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "U4XgyxrCkZJ_",
        "outputId": "15566627-630f-40de-de1a-6ff372aeb9d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://25248ab5327a207398.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://25248ab5327a207398.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}